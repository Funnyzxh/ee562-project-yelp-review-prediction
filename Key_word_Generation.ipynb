{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be0453c2a7f635c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4486b4bb682851e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/xiaohanzhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xiaohanzhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/xiaohanzhang/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d08251837d545f28",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function used to covert json to DataFrame\n",
    "def read_json_to_dataframe(file_path):\n",
    "    try:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function used to remove extra apostrophes\n",
    "def remove_apostrophes(series):\n",
    "    return series.apply(lambda lst: [re.sub(r\"'+\", '', word) \\\n",
    "                                         if word.count(\"'\") >= 2 else word for word in lst])\n",
    "\n",
    "# Function used to regular expression and split review text\n",
    "def Regular_and_split(df, column_name, new_column_name, separator):\n",
    "    df[new_column_name] = (df[column_name].str.lower()\n",
    "                           .str.replace(r\"[^a-zA-Z' ]\", ' ', regex=True)\n",
    "                           .str.replace(r'\\s+', ' ', regex=True)\n",
    "                           .str.strip()\n",
    "                           .str.split(separator))\n",
    "    return df\n",
    "\n",
    "#Funtion used to calculate the sum of votes on different wight\n",
    "def sum_votes(vote_dict):\n",
    "    weights = {'funny': 1, 'useful': 2, 'cool': 1}\n",
    "    return sum(vote_dict.get(key, 0) * weight for key, weight in weights.items())\n",
    "\n",
    "# This class is used for sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "# Stop words are common words used in text processing (such as 'the', 'is', 'in', etc.)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function used to extract the evaluative words\n",
    "def evaluative_words(words):\n",
    "    return [word for word in words if word not in stop_words \\\n",
    "            and sia.polarity_scores(word)['compound'] != 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6664f3f2c99ad11f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Covert json dataset to DataFrame\n",
    "df_business = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_business.json\")\n",
    "df_checkin = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_checkin.json\")\n",
    "df_review = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_review.json\")\n",
    "df_user = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_user.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6bfab15d5e426d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Process on the review dataset\n",
    "df_review = Regular_and_split(df_review, 'text', 'split_text',' ')\n",
    "df_review['split_text'] = remove_apostrophes(df_review['split_text'])\n",
    "df_review['votes_weight'] = df_review['votes'].apply(sum_votes)\n",
    "df_review['text_length'] = df_review['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4032798509c41ee",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_review['evaluative_words'] = df_review['split_text'].apply(evaluative_words)\n",
    "df_words_counts = df_review[\"evaluative_words\"].explode().value_counts()\n",
    "\n",
    "# Extract the top 100 common evaluative words\n",
    "top_words = set(df_words_counts.head(100).index.tolist())\n",
    "df_review['top_words_count'] = df_review['evaluative_words'] \\\n",
    "    .apply(lambda words: sum(word in top_words for word in words) if isinstance(words, list) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54908ddad23627d3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>votes</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>business_id</th>\n",
       "      <th>split_text</th>\n",
       "      <th>votes_weight</th>\n",
       "      <th>text_length</th>\n",
       "      <th>evaluative_words</th>\n",
       "      <th>top_words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'funny': 0, 'useful': 5, 'cool': 2}</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>[my, wife, took, me, here, on, my, birthday, f...</td>\n",
       "      <td>12</td>\n",
       "      <td>889</td>\n",
       "      <td>[excellent, perfect, pleasure, excellent, like...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>[i, have, no, idea, why, some, people, give, b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1345</td>\n",
       "      <td>[bad, please, fault, like, friend, pretty, ple...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'funny': 0, 'useful': 1, 'cool': 0}</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>[love, the, gyro, plate, rice, is, so, good, a...</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>[love, good]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'funny': 0, 'useful': 2, 'cool': 1}</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>[rosie, dakota, and, i, love, chaparral, dog, ...</td>\n",
       "      <td>5</td>\n",
       "      <td>419</td>\n",
       "      <td>[love, wonderful, clean, huge, play]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>[general, manager, scott, petello, is, a, good...</td>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>[good, assure, treat, respect, surprised, sati...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229902</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>6e7pZofhDuIlD_rX2oYirQ</td>\n",
       "      <td>f9JaiNg_FMoPNWxt7MlbZQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-04-14</td>\n",
       "      <td>I really wanted to like this place because it'...</td>\n",
       "      <td>review</td>\n",
       "      <td>vnffHkFJbmd-J3OaBbK2Eg</td>\n",
       "      <td>[i, really, wanted, to, like, this, place, bec...</td>\n",
       "      <td>0</td>\n",
       "      <td>939</td>\n",
       "      <td>[like, honestly, bad, impressed, nice, relaxin...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229903</th>\n",
       "      <td>{'funny': 0, 'useful': 2, 'cool': 0}</td>\n",
       "      <td>dDNfSFT0VApxPmURclX6_g</td>\n",
       "      <td>QDWRP1pW5r0huIBAoGmFyg</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-23</td>\n",
       "      <td>My husband I stayed here for two nights.  Of c...</td>\n",
       "      <td>review</td>\n",
       "      <td>l5oUrgQ190l8CcN8uzd_pA</td>\n",
       "      <td>[my, husband, i, stayed, here, for, two, night...</td>\n",
       "      <td>4</td>\n",
       "      <td>831</td>\n",
       "      <td>[ready, horrible, complain, like, stop, good, ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229904</th>\n",
       "      <td>{'funny': 0, 'useful': 0, 'cool': 0}</td>\n",
       "      <td>M5wHt6Odh1k5v0tIjqd8DQ</td>\n",
       "      <td>JmR3yk7JlS1LVVxtIc3xBQ</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-10-11</td>\n",
       "      <td>Cool atmosphere. A lot of beers on tap and goo...</td>\n",
       "      <td>review</td>\n",
       "      <td>-EctXOb3B7T177jGYUhjVA</td>\n",
       "      <td>[cool, atmosphere, a, lot, of, beers, on, tap,...</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>[cool, good, great]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229905</th>\n",
       "      <td>{'funny': 1, 'useful': 2, 'cool': 0}</td>\n",
       "      <td>jopndPrv-H5KW2CfScnw9A</td>\n",
       "      <td>z5b2p5TbCg0uaIiIe8n62w</td>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-18</td>\n",
       "      <td>I have to take a star off for the spotty servi...</td>\n",
       "      <td>review</td>\n",
       "      <td>YQvg0JCGRFUkb6reMMf3Iw</td>\n",
       "      <td>[i, have, to, take, a, star, off, for, the, sp...</td>\n",
       "      <td>5</td>\n",
       "      <td>420</td>\n",
       "      <td>[irritated, like, disappoint]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229906</th>\n",
       "      <td>{'funny': 1, 'useful': 0, 'cool': 1}</td>\n",
       "      <td>mbRUG6h0Mgb2XIJvscIoMg</td>\n",
       "      <td>QM1rFJsW-ZJoCHbgsysKaw</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-08-14</td>\n",
       "      <td>So cool, yo.</td>\n",
       "      <td>review</td>\n",
       "      <td>gKxOZvQTTd5hpFa3r5igGQ</td>\n",
       "      <td>[so, cool, yo]</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>[cool]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229907 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       votes                 user_id  \\\n",
       "0       {'funny': 0, 'useful': 5, 'cool': 2}  rLtl8ZkDX5vH5nAx9C3q5Q   \n",
       "1       {'funny': 0, 'useful': 0, 'cool': 0}  0a2KyEL0d3Yb1V6aivbIuQ   \n",
       "2       {'funny': 0, 'useful': 1, 'cool': 0}  0hT2KtfLiobPvh6cDC8JQg   \n",
       "3       {'funny': 0, 'useful': 2, 'cool': 1}  uZetl9T0NcROGOyFfughhg   \n",
       "4       {'funny': 0, 'useful': 0, 'cool': 0}  vYmM4KTsC8ZfQBg-j5MWkw   \n",
       "...                                      ...                     ...   \n",
       "229902  {'funny': 0, 'useful': 0, 'cool': 0}  6e7pZofhDuIlD_rX2oYirQ   \n",
       "229903  {'funny': 0, 'useful': 2, 'cool': 0}  dDNfSFT0VApxPmURclX6_g   \n",
       "229904  {'funny': 0, 'useful': 0, 'cool': 0}  M5wHt6Odh1k5v0tIjqd8DQ   \n",
       "229905  {'funny': 1, 'useful': 2, 'cool': 0}  jopndPrv-H5KW2CfScnw9A   \n",
       "229906  {'funny': 1, 'useful': 0, 'cool': 1}  mbRUG6h0Mgb2XIJvscIoMg   \n",
       "\n",
       "                     review_id  stars       date  \\\n",
       "0       fWKvX83p0-ka4JS3dc6E5A      5 2011-01-26   \n",
       "1       IjZ33sJrzXqU-0X6U8NwyA      5 2011-07-27   \n",
       "2       IESLBzqUCLdSzSqm0eCSxQ      4 2012-06-14   \n",
       "3       G-WvGaISbqqaMHlNnByodA      5 2010-05-27   \n",
       "4       1uJFq2r5QfJG_6ExMRCaGw      5 2012-01-05   \n",
       "...                        ...    ...        ...   \n",
       "229902  f9JaiNg_FMoPNWxt7MlbZQ      2 2011-04-14   \n",
       "229903  QDWRP1pW5r0huIBAoGmFyg      1 2011-01-23   \n",
       "229904  JmR3yk7JlS1LVVxtIc3xBQ      4 2010-10-11   \n",
       "229905  z5b2p5TbCg0uaIiIe8n62w      3 2011-01-18   \n",
       "229906  QM1rFJsW-ZJoCHbgsysKaw      5 2010-08-14   \n",
       "\n",
       "                                                     text    type  \\\n",
       "0       My wife took me here on my birthday for breakf...  review   \n",
       "1       I have no idea why some people give bad review...  review   \n",
       "2       love the gyro plate. Rice is so good and I als...  review   \n",
       "3       Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4       General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                   ...     ...   \n",
       "229902  I really wanted to like this place because it'...  review   \n",
       "229903  My husband I stayed here for two nights.  Of c...  review   \n",
       "229904  Cool atmosphere. A lot of beers on tap and goo...  review   \n",
       "229905  I have to take a star off for the spotty servi...  review   \n",
       "229906                                       So cool, yo.  review   \n",
       "\n",
       "                   business_id  \\\n",
       "0       9yKzy9PApeiPPOUJEtnvkg   \n",
       "1       ZRJwVLyzEJq1VAihDhYiow   \n",
       "2       6oRAC4uyJCsJl1X0WZpVSA   \n",
       "3       _1QQZuf4zZOyFCvXc0o6Vg   \n",
       "4       6ozycU1RpktNG2-1BroVtw   \n",
       "...                        ...   \n",
       "229902  vnffHkFJbmd-J3OaBbK2Eg   \n",
       "229903  l5oUrgQ190l8CcN8uzd_pA   \n",
       "229904  -EctXOb3B7T177jGYUhjVA   \n",
       "229905  YQvg0JCGRFUkb6reMMf3Iw   \n",
       "229906  gKxOZvQTTd5hpFa3r5igGQ   \n",
       "\n",
       "                                               split_text  votes_weight  \\\n",
       "0       [my, wife, took, me, here, on, my, birthday, f...            12   \n",
       "1       [i, have, no, idea, why, some, people, give, b...             0   \n",
       "2       [love, the, gyro, plate, rice, is, so, good, a...             2   \n",
       "3       [rosie, dakota, and, i, love, chaparral, dog, ...             5   \n",
       "4       [general, manager, scott, petello, is, a, good...             0   \n",
       "...                                                   ...           ...   \n",
       "229902  [i, really, wanted, to, like, this, place, bec...             0   \n",
       "229903  [my, husband, i, stayed, here, for, two, night...             4   \n",
       "229904  [cool, atmosphere, a, lot, of, beers, on, tap,...             0   \n",
       "229905  [i, have, to, take, a, star, off, for, the, sp...             5   \n",
       "229906                                     [so, cool, yo]             2   \n",
       "\n",
       "        text_length                                   evaluative_words  \\\n",
       "0               889  [excellent, perfect, pleasure, excellent, like...   \n",
       "1              1345  [bad, please, fault, like, friend, pretty, ple...   \n",
       "2                76                                       [love, good]   \n",
       "3               419               [love, wonderful, clean, huge, play]   \n",
       "4               469  [good, assure, treat, respect, surprised, sati...   \n",
       "...             ...                                                ...   \n",
       "229902          939  [like, honestly, bad, impressed, nice, relaxin...   \n",
       "229903          831  [ready, horrible, complain, like, stop, good, ...   \n",
       "229904          124                                [cool, good, great]   \n",
       "229905          420                      [irritated, like, disappoint]   \n",
       "229906           12                                             [cool]   \n",
       "\n",
       "        top_words_count  \n",
       "0                    15  \n",
       "1                    20  \n",
       "2                     2  \n",
       "3                     5  \n",
       "4                     5  \n",
       "...                 ...  \n",
       "229902               10  \n",
       "229903                6  \n",
       "229904                3  \n",
       "229905                1  \n",
       "229906                1  \n",
       "\n",
       "[229907 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f712a79a9f3bbfb1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert to numeric representation\n",
    "df_business['isOpen'] = df_business['open'].astype(int)\n",
    "\n",
    "#Count the total number of checkin days\n",
    "df_checkin['checkin_nums'] = df_checkin['checkin_info'].apply(lambda x: sum(x.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e452247fbc31a6d1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the total votes\n",
    "df_user['votes_total'] = df_user['votes'].apply(lambda x: sum(x.values()))\n",
    "\n",
    "# Calculate the ratio of votes to review_count\n",
    "df_user['votes_per_review'] = df_user['votes_total'] / df_user['review_count']\n",
    "\n",
    "# If division by 0\n",
    "df_user['votes_per_review'] = df_user['votes_per_review'].replace([pd.NaT, pd.NaT], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7ea4dca90208694",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_review = df_review[['user_id', 'business_id', 'stars', 'votes_weight', 'text_length', 'top_words_count']].copy()\n",
    "temp_business = df_business[['business_id', 'review_count', 'isOpen']].copy()\n",
    "temp_checkin = df_checkin[['business_id', 'checkin_nums']].copy()\n",
    "temp_user = df_user[['user_id', 'votes_per_review']].copy()\n",
    "\n",
    "# Obtain a total dataset used for machine learning by merging above four dataset\n",
    "merged_df = pd.merge(temp_review, temp_business, on = 'business_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_user, on = 'user_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_checkin, on = 'business_id', how = 'inner')\n",
    "#merged_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1facb8306ce57e7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-09T12:02:08.592501Z",
     "start_time": "2023-12-09T12:02:08.487290Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 1: Numbers: [0], Sum = 72038\n",
      "Group 2: Numbers: [1, 2, 3], Sum = 54846\n",
      "Group 3: Numbers: [4, 5, 6, 7, 8, 9, 10], Sum = 52942\n",
      "Group 4: Numbers: [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 123, 125, 126, 129, 131, 133, 135, 141, 150, 154, 164, 171, 175, 187, 196, 198, 200, 202, 203, 241], Sum = 20647\n"
     ]
    }
   ],
   "source": [
    "# Function used to determine votes weight distribution\n",
    "def divide_series(series, n_groups):\n",
    "    total_count = series.sum()\n",
    "    target_per_group = total_count / n_groups\n",
    "\n",
    "    groups = {i: [] for i in range(n_groups)}\n",
    "    group_sums = [0] * n_groups\n",
    "    current_group = 0\n",
    "\n",
    "    for number, count in series.items():\n",
    "        groups[current_group].append(number)\n",
    "        group_sums[current_group] += count\n",
    "        if group_sums[current_group] >= target_per_group and current_group < n_groups - 1:\n",
    "            current_group += 1\n",
    "\n",
    "    return {f\"Group {i + 1}\": {\"Numbers\": groups[i], \"Sum\": group_sums[i]} for i in range(n_groups)}\n",
    "\n",
    "series = merged_df['votes_weight'].value_counts().sort_index()\n",
    "groups = divide_series(series, 4)\n",
    "\n",
    "for group_name, group_info in groups.items():\n",
    "    print(f\"{group_name}: Numbers: {group_info['Numbers']}, Sum = {group_info['Sum']}\")\n",
    "\n",
    "number_to_group = {num: i+1 for i, (group, info) in enumerate(groups.items()) for num in info[\"Numbers\"]}\n",
    "merged_df['votes_category'] = merged_df['votes_weight'].apply(lambda x: number_to_group.get(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986a3ff159553cb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478e9462e5f36c8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
