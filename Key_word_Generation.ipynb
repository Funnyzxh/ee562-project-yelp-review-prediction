{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be0453c2a7f635c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4486b4bb682851e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function used to covert json to DataFrame\n",
    "def read_json_to_dataframe(file_path):\n",
    "    try:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function used to remove extra apostrophes\n",
    "def remove_apostrophes(series):\n",
    "    return series.apply(lambda lst: [re.sub(r\"'+\", '', word) \\\n",
    "                                         if word.count(\"'\") >= 2 else word for word in lst])\n",
    "\n",
    "# Function used to regular expression and split review text\n",
    "def Regular_and_split(df, column_name, new_column_name, separator):\n",
    "    df[new_column_name] = (df[column_name].str.lower()\n",
    "                           .str.replace(r\"[^a-zA-Z' ]\", ' ', regex=True)\n",
    "                           .str.replace(r'\\s+', ' ', regex=True)\n",
    "                           .str.strip()\n",
    "                           .str.split(separator))\n",
    "    return df\n",
    "\n",
    "#Funtion used to calculate the sum of votes on different wight\n",
    "def sum_votes(vote_dict):\n",
    "    weights = {'funny': 1, 'useful': 2, 'cool': 1}\n",
    "    return sum(vote_dict.get(key, 0) * weight for key, weight in weights.items())\n",
    "\n",
    "# This class is used for sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "# Stop words are common words used in text processing (such as 'the', 'is', 'in', etc.)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function used to extract the evaluative words\n",
    "def evaluative_words(words):\n",
    "    return [word for word in words if word not in stop_words \\\n",
    "            and sia.polarity_scores(word)['compound'] != 0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d08251837d545f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Covert json dataset to DataFrame\n",
    "df_business = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_business.json\")\n",
    "df_checkin = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_checkin.json\")\n",
    "df_review = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_review.json\")\n",
    "df_user = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_user.json\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6664f3f2c99ad11f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Process on the review dataset\n",
    "df_review = Regular_and_split(df_review, 'text', 'split_text',' ')\n",
    "df_review['split_text'] = remove_apostrophes(df_review['split_text'])\n",
    "df_review['votes_weight'] = df_review['votes'].apply(sum_votes)\n",
    "df_review['text_length'] = df_review['text'].apply(len)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6bfab15d5e426d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review['evaluative_words'] = df_review['split_text'].apply(evaluative_words)\n",
    "df_words_counts = df_review[\"evaluative_words\"].explode().value_counts()\n",
    "\n",
    "# Extract the top 100 common evaluative words\n",
    "top_words = set(df_words_counts.head(100).index.tolist())\n",
    "df_review['top_words_count'] = df_review['evaluative_words'] \\\n",
    "    .apply(lambda words: sum(word in top_words for word in words) if isinstance(words, list) else 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4032798509c41ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54908ddad23627d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Convert to numeric representation\n",
    "df_business['isOpen'] = df_business['open'].astype(int)\n",
    "\n",
    "#Count the total number of checkin days\n",
    "df_checkin['checkin_nums'] = df_checkin['checkin_info'].apply(lambda x: sum(x.values()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f712a79a9f3bbfb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the total votes\n",
    "df_user['votes_total'] = df_user['votes'].apply(lambda x: sum(x.values()))\n",
    "\n",
    "# Calculate the ratio of votes to review_count\n",
    "df_user['votes_per_review'] = df_user['votes_total'] / df_user['review_count']\n",
    "\n",
    "# If division by 0\n",
    "df_user['votes_per_review'] = df_user['votes_per_review'].replace([pd.NaT, pd.NaT], 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e452247fbc31a6d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_review = df_review[['user_id', 'business_id', 'stars', 'votes_weight', 'text_length', 'top_words_count']].copy()\n",
    "temp_business = df_business[['business_id', 'review_count', 'isOpen']].copy()\n",
    "temp_checkin = df_checkin[['business_id', 'checkin_nums']].copy()\n",
    "temp_user = df_user[['user_id', 'votes_per_review']].copy()\n",
    "\n",
    "# Obtain a total dataset used for machine learning by merging above four dataset\n",
    "merged_df = pd.merge(temp_review, temp_business, on = 'business_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_user, on = 'user_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_checkin, on = 'business_id', how = 'inner')\n",
    "#merged_df.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7ea4dca90208694"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmerged_df\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Function used to determine votes weight distribution\n",
    "def divide_series(series, n_groups):\n",
    "    total_count = series.sum()\n",
    "    target_per_group = total_count / n_groups\n",
    "\n",
    "    groups = {i: [] for i in range(n_groups)}\n",
    "    group_sums = [0] * n_groups\n",
    "    current_group = 0\n",
    "\n",
    "    for number, count in series.items():\n",
    "        groups[current_group].append(number)\n",
    "        group_sums[current_group] += count\n",
    "        if group_sums[current_group] >= target_per_group and current_group < n_groups - 1:\n",
    "            current_group += 1\n",
    "\n",
    "    return {f\"Group {i + 1}\": {\"Numbers\": groups[i], \"Sum\": group_sums[i]} for i in range(n_groups)}\n",
    "\n",
    "series = merged_df['votes_weight'].value_counts().sort_index()\n",
    "groups = divide_series(series, 4)\n",
    "\n",
    "for group_name, group_info in groups.items():\n",
    "    print(f\"{group_name}: Numbers: {group_info['Numbers']}, Sum = {group_info['Sum']}\")\n",
    "\n",
    "number_to_group = {num: i+1 for i, (group, info) in enumerate(groups.items()) for num in info[\"Numbers\"]}\n",
    "merged_df['votes_category'] = merged_df['votes_weight'].apply(lambda x: number_to_group.get(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T12:02:08.592501Z",
     "start_time": "2023-12-09T12:02:08.487290Z"
    }
   },
   "id": "1facb8306ce57e7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "986a3ff159553cb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a478e9462e5f36c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
