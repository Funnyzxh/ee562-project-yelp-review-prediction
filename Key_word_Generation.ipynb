{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be0453c2a7f635c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4486b4bb682851e9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_json_to_dataframe(file_path):\n",
    "    try:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        return None\n",
    "\n",
    "def remove_apostrophes(series):\n",
    "    return series.apply(lambda lst: [re.sub(r\"'+\", '', word) \\\n",
    "                                         if word.count(\"'\") >= 2 else word for word in lst])\n",
    "\n",
    "def De_symbolize_and_split(df, column_name, new_column_name, separator):\n",
    "    df[new_column_name] = (df[column_name].str.lower()\n",
    "                           .str.replace(r\"[^a-zA-Z' ]\", ' ', regex=True)\n",
    "                           .str.replace(r'\\s+', ' ', regex=True)\n",
    "                           .str.strip()\n",
    "                           .str.split(separator))\n",
    "    return df\n",
    "\n",
    "def sum_votes(vote_dict):\n",
    "    weights = {'funny': 1, 'useful': 2, 'cool': 1}\n",
    "    return sum(vote_dict.get(key, 0) * weight for key, weight in weights.items())\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def evaluative_words(words):\n",
    "    return [word for word in words if word not in stop_words \\\n",
    "            and sia.polarity_scores(word)['compound'] != 0]\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d08251837d545f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_business = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_business.json\")\n",
    "df_checkin = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_checkin.json\")\n",
    "df_review = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_review.json\")\n",
    "df_user = read_json_to_dataframe(\"yelp-dataset/yelp_training_set/yelp_training_set_user.json\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6664f3f2c99ad11f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review = De_symbolize_and_split(df_review, 'text', 'split_text',' ')\n",
    "df_review['split_text'] = remove_apostrophes(df_review['split_text'])\n",
    "df_review['votes_weight'] = df_review['votes'].apply(sum_votes)\n",
    "df_review['text_length'] = df_review['text'].apply(len)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6bfab15d5e426d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review['evaluative_words'] = df_review['split_text'].apply(evaluative_words)\n",
    "df_words_counts = df_review[\"evaluative_words\"].explode().value_counts()\n",
    "top_words = set(df_words_counts.head(100).index.tolist())\n",
    "df_review['top_words_count'] = df_review['evaluative_words'] \\\n",
    "    .apply(lambda words: sum(word in top_words for word in words) if isinstance(words, list) else 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4032798509c41ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_review"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54908ddad23627d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Convert to numeric representation\n",
    "df_business['isOpen'] = df_business['open'].astype(int)\n",
    "\n",
    "#Count the total number of checkin days\n",
    "df_checkin['checkin_nums'] = df_checkin['checkin_info'].apply(lambda x: sum(x.values()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f712a79a9f3bbfb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate the total votes\n",
    "df_user['votes_total'] = df_user['votes'].apply(lambda x: sum(x.values()))\n",
    "\n",
    "# Calculate the ratio of votes to review_count\n",
    "df_user['votes_per_review'] = df_user['votes_total'] / df_user['review_count']\n",
    "\n",
    "# If division by 0\n",
    "df_user['votes_per_review'] = df_user['votes_per_review'].replace([pd.NaT, pd.NaT], 0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e452247fbc31a6d1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_review = df_review[['user_id', 'business_id', 'stars', 'votes_weight', 'text_length', 'top_words_count']].copy()\n",
    "temp_business = df_business[['business_id', 'review_count', 'isOpen']].copy()\n",
    "temp_checkin = df_checkin[['business_id', 'checkin_nums']].copy()\n",
    "temp_user = df_user[['user_id', 'votes_per_review']].copy()\n",
    "\n",
    "merged_df = pd.merge(temp_review, temp_business, on = 'business_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_user, on = 'user_id', how = 'inner')\n",
    "merged_df = pd.merge(merged_df, temp_checkin, on = 'business_id', how = 'inner')\n",
    "#merged_df.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7ea4dca90208694"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmerged_df\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'merged_df' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-09T12:02:08.592501Z",
     "start_time": "2023-12-09T12:02:08.487290Z"
    }
   },
   "id": "1facb8306ce57e7b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "986a3ff159553cb0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a478e9462e5f36c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
